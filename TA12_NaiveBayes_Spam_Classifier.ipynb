{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df47ef82",
   "metadata": {},
   "source": [
    "# TA-12 — Klasifikasi SMS Spam (Naive Bayes)\n",
    "\n",
    "1) Load data + Encoding + Split 80/20\n",
    "2) Train Multinomial Naive Bayes\n",
    "3) Evaluasi (Confusion Matrix + Accuracy) + Analisis predict_proba\n",
    "4) Simulasi prediksi data baru (2 dummy kontras)\n",
    "\n",
    "Dataset: **SMS Spam Collection** (file `spam.csv` dengan kolom `v1` (ham/spam) dan `v2` (teks)).\n",
    "\n",
    "> Catatan penting: Karena ini data teks, saya pakai **MultinomialNB**. **Feature scaling (StandardScaler) tidak diperlukan** dan biasanya wajibnya untuk **GaussianNB** pada data numerik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1f9a95",
   "metadata": {},
   "source": [
    "## 0) Instalasi \n",
    "install ini:\n",
    "\n",
    "```bash\n",
    "pip install pandas scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef083cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Import library\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ae0db",
   "metadata": {},
   "source": [
    "## 1) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd6450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Load data\n",
    "# Pastikan file 'spam.csv' ada di folder yang sama dengan notebook ini.\n",
    "data = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
    "\n",
    "# Ambil kolom penting saja: v1 (label) dan v2 (text)\n",
    "data = data[['v1', 'v2']].copy()\n",
    "data.columns = ['label', 'text']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d3e3d",
   "metadata": {},
   "source": [
    "## 2) Encoding label (wajib)\n",
    "encoding menjadi numerik. pakai **LabelEncoder**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31856804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ham': 0, 'spam': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "data['label_encoded'] = le.fit_transform(data['label'])\n",
    "\n",
    "label_mapping = {cls: int(idx) for idx, cls in enumerate(le.classes_)}\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239bba9",
   "metadata": {},
   "source": [
    "## 3) Split data 80% training / 20% testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc3444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 1115)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text = data['text']\n",
    "y = data['label_encoded']\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "len(X_train_text), len(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12884759",
   "metadata": {},
   "source": [
    "## 4) Ekstraksi fitur teks → angka (CountVectorizer)\n",
    "Teks diubah menjadi angka berdasarkan **frekuensi kata** (bag-of-words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4565968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 7701), (1115, 7701))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit hanya pada TRAIN untuk menghindari data leakage\n",
    "X_train = vectorizer.fit_transform(X_train_text)\n",
    "X_test = vectorizer.transform(X_test_text)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b2dd8",
   "metadata": {},
   "source": [
    "## 5) Train model Naive Bayes (MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0f7355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil dilatih.\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model berhasil dilatih.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0105515f",
   "metadata": {},
   "source": [
    "## 6) Evaluasi (Confusion Matrix + Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77f9757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (baris=actual, kolom=pred):\n",
      "[[961   5]\n",
      " [ 13 136]]\n",
      "\n",
      "Accuracy: 0.9838565022421525\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix (baris=actual, kolom=pred):\")\n",
    "print(cm)\n",
    "print(\"\\nAccuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3cb58e",
   "metadata": {},
   "source": [
    "## 7) Analisis probabilitas (predict_proba)\n",
    "Ambil 1 sampel test yang **salah prediksi** (jika ada). Jika tidak ada, ambil sampel acak.\n",
    "Lalu tampilkan `predict_proba` dan lihat apakah model **yakin** atau **ragu-ragu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91fe17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jenis sampel: Sampel SALAH prediksi (dari test set)\n",
      "\n",
      "Teks sampel:\n",
      " FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv\n",
      "\n",
      "Actual: spam\n",
      "Pred  : ham\n",
      "\n",
      "predict_proba:\n",
      "P(ham) = 99.95%\n",
      "P(spam) = 0.05%\n",
      "\n",
      "Interpretasi cepat:\n",
      "- Model cukup yakin (beda probabilitas besar).\n"
     ]
    }
   ],
   "source": [
    "# Cari indeks yang salah prediksi\n",
    "mis_idx = [i for i, (a, b) in enumerate(zip(y_test, y_pred)) if a != b]\n",
    "\n",
    "if len(mis_idx) > 0:\n",
    "    chosen_i = mis_idx[0]\n",
    "    chosen_type = \"Sampel SALAH prediksi (dari test set)\"\n",
    "else:\n",
    "    chosen_i = random.randint(0, len(y_test) - 1)\n",
    "    chosen_type = \"Sampel ACAK (tidak ada yang salah prediksi)\"\n",
    "\n",
    "sample_text = X_test_text.iloc[chosen_i]\n",
    "sample_true = int(y_test.iloc[chosen_i])\n",
    "sample_pred = int(y_pred[chosen_i])\n",
    "\n",
    "sample_vec = vectorizer.transform([sample_text])\n",
    "proba = model.predict_proba(sample_vec)[0]  # [P(class0), P(class1)]\n",
    "\n",
    "class0_label = le.inverse_transform([0])[0]\n",
    "class1_label = le.inverse_transform([1])[0]\n",
    "\n",
    "print(\"Jenis sampel:\", chosen_type)\n",
    "print(\"\\nTeks sampel:\\n\", sample_text)\n",
    "print(\"\\nActual:\", le.inverse_transform([sample_true])[0])\n",
    "print(\"Pred  :\", le.inverse_transform([sample_pred])[0])\n",
    "print(\"\\npredict_proba:\")\n",
    "print(f\"P({class0_label}) = {proba[0]*100:.2f}%\")\n",
    "print(f\"P({class1_label}) = {proba[1]*100:.2f}%\")\n",
    "\n",
    "print(\"\\nInterpretasi cepat:\")\n",
    "if abs(proba[0]-proba[1]) < 0.1:\n",
    "    print(\"- Model cenderung ragu-ragu (dekat 50%-50%).\")\n",
    "else:\n",
    "    print(\"- Model cukup yakin (beda probabilitas besar).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e742c",
   "metadata": {},
   "source": [
    "## 8) Simulasi prediksi data baru (2 dummy kontras)\n",
    "\n",
    "\n",
    "- **Dummy A**: sangat 'spammy'\n",
    "- **Dummy B**: chat normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "528546cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy A: CONGRATULATIONS! You WIN FREE cash prize, claim now, urgent, call now!\n",
      "Prediksi: spam\n",
      "Proba -> P(ham)=0.00%, P(spam)=100.00%\n",
      "\n",
      "Dummy B: Hai, nanti pulang sekolah jadi makan bakso bareng ya?\n",
      "Prediksi: ham\n",
      "Proba -> P(ham)=99.69%, P(spam)=0.31%\n"
     ]
    }
   ],
   "source": [
    "def predict_text(text):\n",
    "    vec = vectorizer.transform([text])\n",
    "    pred = int(model.predict(vec)[0])\n",
    "    prob = model.predict_proba(vec)[0]\n",
    "    return le.inverse_transform([pred])[0], prob\n",
    "\n",
    "dummy_A = \"CONGRATULATIONS! You WIN FREE cash prize, claim now, urgent, call now!\"\n",
    "dummy_B = \"Hai, nanti pulang sekolah jadi makan bakso bareng ya?\"\n",
    "\n",
    "pred_A, prob_A = predict_text(dummy_A)\n",
    "pred_B, prob_B = predict_text(dummy_B)\n",
    "\n",
    "print(\"Dummy A:\", dummy_A)\n",
    "print(\"Prediksi:\", pred_A)\n",
    "print(f\"Proba -> P({class0_label})={prob_A[0]*100:.2f}%, P({class1_label})={prob_A[1]*100:.2f}%\")\n",
    "\n",
    "print(\"\\nDummy B:\", dummy_B)\n",
    "print(\"Prediksi:\", pred_B)\n",
    "print(f\"Proba -> P({class0_label})={prob_B[0]*100:.2f}%, P({class1_label})={prob_B[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c07cbf3",
   "metadata": {},
   "source": [
    "## 9) Kesimpulan singkat \n",
    "- Kata-kata seperti **FREE**, **WIN**, **PRIZE**, **URGENT**, **CALL NOW** biasanya kuat mendorong prediksi ke **spam**.\n",
    "- Kalimat percakapan normal cenderung mendorong prediksi ke **ham**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
